**MNIST Handwritten Digit Classification using CNNs and Comparative Analysis of Neural Architectures**

- **Objective**: Developed a high-accuracy classification model for the MNIST dataset using a Convolutional Neural Network (CNN) and conducted in-depth tests to compare the performance of various neural architectures.
  
- **Methods**:
  - **CNN Implementation**: Designed and trained a CNN model tailored for the MNIST dataset, focusing on optimizing the network depth and complexity.
  - **Architecture Depth Tests**: Systematically evaluated different CNN architectures by varying the depth (number of convolutional and pooling layers) to determine the impact on model accuracy and training efficiency.
  - **Comparative Analysis**: Explored the effectiveness of traditional neural architectures, including:
    - **Flat Dense Network (Feedforward Neural Network, FFN)**: Implemented and evaluated a standard dense network to serve as a baseline for performance comparison.
    - **Vision Transformer (ViT)**: Investigated the application of Vision Transformers on the MNIST dataset, analyzing their performance relative to CNNs and FFNs.
  
- **Results**:
  - Achieved high classification accuracy with the CNN model, establishing it as a robust solution for the MNIST problem.
  - Determined optimal depth configurations for CNNs that balance performance and computational efficiency.
  - Demonstrated that while traditional FFNs provide a straightforward approach, CNNs outperform them significantly on image data.
  - Highlighted the potential of Vision Transformers for image classification tasks, noting their competitive performance and unique advantages over CNNs in certain aspects.
  
- **Technologies Used**: Python, TensorFlow, Keras, PyTorch, Jupyter Notebook.


